{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E2E Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import Input, Model, Sequential\n",
    "from tensorflow.keras.backend import placeholder\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import (Concatenate, Conv2D, Dense, Dropout,\n",
    "                                     Flatten, MaxPooling2D, Reshape,\n",
    "                                     UpSampling2D)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "\n",
    "from helpers import can_be_concatenated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [160,160,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14],\n",
       "        [15, 16, 17, 18, 19]],\n",
       "\n",
       "       [[20, 21, 22, 23, 24],\n",
       "        [25, 26, 27, 28, 29],\n",
       "        [30, 31, 32, 33, 34],\n",
       "        [35, 36, 37, 38, 39]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(40).reshape(2,4,5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0,  1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8,  9]],\n",
       "\n",
       "        [[10, 11, 12, 13, 14],\n",
       "         [15, 16, 17, 18, 19]]],\n",
       "\n",
       "\n",
       "       [[[20, 21, 22, 23, 24],\n",
       "         [25, 26, 27, 28, 29]],\n",
       "\n",
       "        [[30, 31, 32, 33, 34],\n",
       "         [35, 36, 37, 38, 39]]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(40).reshape(2,2,2,5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(20).reshape(2,10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.arange(10)\n",
    "z = np.arange(10,20)\n",
    "np.stack((y,z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ways to reshape layers\n",
    "\n",
    "For concatenation the first two array dimensions `[x,x,y]` must be the same in both arrays. The goal is here to resize `branch2` from `[1,1,y]` to `[2,2,y]` to match the shape of `branch1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 2, 2, 512])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branch1 = placeholder((None, 2,2,512))\n",
    "branch1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 1, 1, 256])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branch2 = placeholder((None, 1,1,256))\n",
    "branch2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Reshape\n",
    "Just like with numpy arrays, the sum of the elements in the array must stay the same. This may either be calculated explicitly (`256/(2*2)=64`) or implicitly (`[2,2,-1]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 2, 2, 64])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reshape((2,2,64))(branch2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 2, 2, 256])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UpSampling2D(size=(2,2))(branch2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [160,160,8]\n",
    "inputs = Input(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 158, 158, 32])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 32,3,1: filters, kernel_size, strides\n",
    "conv1 = Conv2D(32, 3, 1, activation='relu')(inputs)\n",
    "conv1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 79, 79, 32])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool1 = MaxPooling2D(2)(conv1)\n",
    "pool1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 160, 160, 32])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# strides: 1 -> 160,160,32\n",
    "# strides: 2 ->  80, 80,32\n",
    "conv1 = Conv2D(32, 3, 1, padding='same',activation='relu')(inputs)\n",
    "conv1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 78, 78, 32])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without padding\n",
    "inputs = Input(input_shape)\n",
    "conv1 = Conv2D(32, 3, 1, activation='relu')(inputs)\n",
    "conv1 = Conv2D(32, 3, 1, activation='relu')(conv1)\n",
    "pool1 = MaxPooling2D(2)(conv1)\n",
    "pool1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 9, 9, 32])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With padding\n",
    "inputs = Input(input_shape)\n",
    "conv1 = Conv2D(32, 3, 3, activation='relu', padding='same')(inputs)\n",
    "conv1 = Conv2D(32, 3, 3, activation='relu', padding='same')(conv1)\n",
    "pool1 = MaxPooling2D(2)(conv1)\n",
    "pool1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Concatenate](https://keras.io/api/layers/merging_layers/concatenate/)\n",
    "Replaces and splits old `concatenate` function in two separate steps\n",
    "``` python\n",
    "up6 = concat([UpSampling2D(size=(2, 2))(conv5), conv4], axis=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate with numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9]],\n",
       "\n",
       "       [[10, 11, 12, 13, 14],\n",
       "        [15, 16, 17, 18, 19]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(20).reshape(2,2,5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[20, 21, 22, 23, 24]],\n",
       "\n",
       "       [[25, 26, 27, 28, 29]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.arange(20,30).reshape(2,1,5)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 5), dtype=int64, numpy=\n",
       "array([[[ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9],\n",
       "        [20, 21, 22, 23, 24]],\n",
       "\n",
       "       [[10, 11, 12, 13, 14],\n",
       "        [15, 16, 17, 18, 19],\n",
       "        [25, 26, 27, 28, 29]]])>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x:  [2,2,5]\n",
    "# y:  [2,1,5]\n",
    "# c1: [2,3,5]\n",
    "c1 = Concatenate(axis=1)([x,y])\n",
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 8), dtype=int64, numpy=\n",
       "array([[[ 0,  1,  2,  3,  4,  0,  1,  2],\n",
       "        [ 5,  6,  7,  8,  9,  3,  4,  5]],\n",
       "\n",
       "       [[10, 11, 12, 13, 14,  6,  7,  8],\n",
       "        [15, 16, 17, 18, 19,  9, 10, 11]]])>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x:  [2,2,5]\n",
    "# y:  [2,2,3]\n",
    "# c1: [2,2,8]\n",
    "y = np.arange(12).reshape(2,2,3)\n",
    "Concatenate()([x,y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate with Layers\n",
    "\n",
    "Dense reshapes lenght of 'row':\n",
    "``` python\n",
    "Dense(4)([2,5]) -> [2,4]\n",
    "Dense(4)([2,2,5]) -> [2,2,4]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[ 2.0660434 ,  0.93344647,  1.5203841 , -1.6713781 ],\n",
       "       [ 9.013583  ,  5.944206  ,  3.66602   , -5.731333  ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = Dense(4)(np.arange(10).reshape(2,5))\n",
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 4), dtype=float32, numpy=\n",
       "array([[[ 4.508412 ,  0.98213  , -1.038495 ,  3.0725205]],\n",
       "\n",
       "       [[ 4.64798  , -2.4304776, -7.3548145,  9.16238  ]]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = Dense(4)(np.arange(12).reshape(2,1,6))\n",
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 4), dtype=float32, numpy=\n",
       "array([[[  2.428606 ,  -0.8935258,  -1.4349568,  -1.4575117],\n",
       "        [  5.1187563,  -4.587531 ,  -3.8905606,  -5.498067 ]],\n",
       "\n",
       "       [[  7.8089066,  -8.281536 ,  -6.3461637,  -9.538623 ],\n",
       "        [ 10.499056 , -11.975542 ,  -8.801768 , -13.579178 ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = Dense(4)(np.arange(12).reshape(2,2,3))\n",
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[-3.87296   , -3.4430141 , -5.340579  ,  0.7713928 ],\n",
       "       [-5.935388  , -4.8587465 , -8.091616  , -0.01273584]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = Dense(4)(np.arange(10,20).reshape(2,5))\n",
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3, 4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l1: [2,4]     l1: [2,1,4]\n",
    "# l2: [2,4]     l2: [2,2,4]\n",
    "# c1: [2,8]     c2: [2,3,4]\n",
    "c1 = Concatenate(axis=1)([l1,l2])\n",
    "c1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 10), dtype=float32, numpy=\n",
       "array([[[  0.9441469 ,  -1.0348364 ,  -0.71980906,  -2.946177  ,\n",
       "          -0.57409763,   0.73893136,  -1.7897422 ,   3.3263345 ,\n",
       "           0.5791789 ,   1.8379655 ],\n",
       "        [  3.390298  ,  -0.9375906 ,   0.62057656, -10.316733  ,\n",
       "          -4.0599937 ,  -0.4908061 ,  -2.1736078 ,   7.6372643 ,\n",
       "          -0.40104008,   5.0435057 ]],\n",
       "\n",
       "       [[  5.8364487 ,  -0.8403449 ,   1.9609623 , -17.68729   ,\n",
       "          -7.54589   ,  -1.7205439 ,  -2.5574734 ,  11.948193  ,\n",
       "          -1.381259  ,   8.249046  ],\n",
       "        [  8.282599  ,  -0.74310017,   3.3013482 , -25.057846  ,\n",
       "         -11.031787  ,  -2.9502811 ,  -2.941339  ,  16.259125  ,\n",
       "          -2.3614779 ,  11.454586  ]]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "l1 = Dense(4)(np.arange(16).reshape(2,2,4))\n",
    "l2 = Dense(6)(np.arange(16).reshape(2,2,4))\n",
    "# l1: [2,2,4]\n",
    "# l2: [2,2,6]\n",
    "# c2: [2,2,10]\n",
    "c2 = Concatenate()([l1,l2])\n",
    "c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 9, 9, 32])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = Input(input_shape)\n",
    "conv1 = Conv2D(32, 3, 3, activation='relu', padding='same')(inputs)\n",
    "conv1 = Conv2D(32, 3, 3, activation='relu', padding='same')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2), padding='same')(conv1)\n",
    "pool1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate the real layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        [(None, 160, 160, 8)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_110 (Conv2D)          (None, 54, 54, 32)        2336      \n",
      "_________________________________________________________________\n",
      "conv2d_111 (Conv2D)          (None, 18, 18, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_112 (Conv2D)          (None, 3, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "conv2d_113 (Conv2D)          (None, 1, 1, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_114 (Conv2D)          (None, 1, 1, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_115 (Conv2D)          (None, 1, 1, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_116 (Conv2D)          (None, 1, 1, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_117 (Conv2D)          (None, 1, 1, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_118 (Conv2D)          (None, 1, 1, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_119 (Conv2D)          (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 2, 2, 512)         0         \n",
      "=================================================================\n",
      "Total params: 4,713,664\n",
      "Trainable params: 4,713,664\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(input_shape)\n",
    "conv1 = Conv2D(32, 3, 3, activation='relu', padding='same')(inputs)\n",
    "conv1 = Conv2D(32, 3, 3, activation='relu', padding='same')(conv1)\n",
    "pool1 = MaxPooling2D(2, padding='same')(conv1)\n",
    "assert conv1.shape.as_list() == [None, 18, 18, 32]\n",
    "\n",
    "conv2 = Conv2D(64, 3, 3, activation='relu', padding='same')(pool1)\n",
    "conv2 = Conv2D(64, 3, 3, activation='relu', padding='same')(conv2)\n",
    "pool2 = MaxPooling2D(2, padding='same')(conv2)\n",
    "\n",
    "conv3 = Conv2D(128, 3, 3, activation='relu', padding='same')(pool2)\n",
    "conv3 = Conv2D(128, 3, 3, activation='relu', padding='same')(conv3)\n",
    "pool3 = MaxPooling2D(2, padding='same')(conv3)\n",
    "\n",
    "conv4 = Conv2D(256, 3, 3, activation='relu', padding='same')(pool3)\n",
    "conv4 = Conv2D(256, 3, 3, activation='relu', padding='same')(conv4)\n",
    "assert conv4.shape.as_list() == [None, 1, 1, 256]\n",
    "pool4 = MaxPooling2D(2, padding='same')(conv4)\n",
    "\n",
    "conv5 = Conv2D(512, 3, 3, activation='relu', padding='same')(pool4)\n",
    "conv5 = Conv2D(512, 3, 3, activation='relu', padding='same')(conv5)\n",
    "conv5 = UpSampling2D(2)(conv5)\n",
    "assert conv5.shape.as_list() == [None, 2, 2, 512]\n",
    "\n",
    "model = Model(inputs,outputs=conv5)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 1, 1, 256])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv4 = Conv2D(256, 3, 3, activation='relu', padding='same')(pool3)\n",
    "conv4 = Conv2D(256, 3, 3, activation='relu', padding='same')(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2), padding='same')(conv4)\n",
    "\n",
    "conv4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 1, 1, 512])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv5 = Conv2D(512, 3, 3, activation='relu', padding='same')(pool4)\n",
    "conv5 = Conv2D(512, 3, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "conv5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 2, 2, 512])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl_conv5 = UpSampling2D(2)(conv5)\n",
    "smpl_conv5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 2, 2, 576) dtype=float32 (created by layer 'concatenate_8')>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_conv4 = Reshape((2,2,64))(conv4)\n",
    "Concatenate()([smpl_conv5, rs_conv4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 2, 2, 768) dtype=float32 (created by layer 'concatenate_19')>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [None,2,2,256] would work\n",
    "X = placeholder(shape=[None, 2, 2, 1], name=\"Placeholder for conv4\")\n",
    "test_conv4 = Dense(256)(X)\n",
    "Concatenate()([smpl_conv5, test_conv4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 9, 9, 32])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = Input(input_shape)\n",
    "conv1 = Conv2D(32, 3, 3, activation='relu', padding='same')(inputs)\n",
    "conv1 = Conv2D(32, 3, 3, activation='relu', padding='same')(conv1)\n",
    "pool1 = MaxPooling2D(2)(conv1)\n",
    "pool1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_42 (InputLayer)           [(None, 160, 160, 8) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 54, 54, 32)   2336        input_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 18, 18, 32)   9248        conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_112 (MaxPooling2D (None, 9, 9, 32)     0           conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 3, 3, 64)     18496       max_pooling2d_112[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 1, 1, 64)     36928       conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_113 (MaxPooling2D (None, 1, 1, 64)     0           conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 1, 1, 128)    73856       max_pooling2d_113[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 1, 1, 128)    147584      conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_114 (MaxPooling2D (None, 1, 1, 128)    0           conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 1, 1, 256)    295168      max_pooling2d_114[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 1, 1, 256)    590080      conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_115 (MaxPooling2D (None, 1, 1, 256)    0           conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 1, 1, 512)    1180160     max_pooling2d_115[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 1, 1, 512)    2359808     conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 1, 1, 768)    0           conv2d_284[0][0]                 \n",
      "                                                                 conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 1, 1, 256)    1769728     concatenate_17[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 6,483,392\n",
      "Trainable params: 6,483,392\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(input_shape)\n",
    "conv1 = Conv2D(32, 3, 3, activation='relu', padding='same')(inputs)\n",
    "conv1 = Conv2D(32, 3, 3, activation='relu', padding='same')(conv1)\n",
    "pool1 = MaxPooling2D(2, padding='same')(conv1)\n",
    "assert conv1.shape.as_list() == [None, 18, 18, 32]\n",
    "\n",
    "conv2 = Conv2D(64, 3, 3, activation='relu', padding='same')(pool1)\n",
    "conv2 = Conv2D(64, 3, 3, activation='relu', padding='same')(conv2)\n",
    "pool2 = MaxPooling2D(2, padding='same')(conv2)\n",
    "\n",
    "conv3 = Conv2D(128, 3, 3, activation='relu', padding='same')(pool2)\n",
    "conv3 = Conv2D(128, 3, 3, activation='relu', padding='same')(conv3)\n",
    "pool3 = MaxPooling2D(2, padding='same')(conv3)\n",
    "\n",
    "conv4 = Conv2D(256, 3, 3, activation='relu', padding='same')(pool3)\n",
    "conv4 = Conv2D(256, 3, 3, activation='relu', padding='same')(conv4)\n",
    "assert conv4.shape.as_list() == [None, 1, 1, 256]\n",
    "pool4 = MaxPooling2D(2, padding='same')(conv4)\n",
    "\n",
    "conv5 = Conv2D(512, 3, 3, activation='relu', padding='same')(pool4)\n",
    "conv5 = Conv2D(512, 3, 3, activation='relu', padding='same')(conv5)\n",
    "assert conv5.shape.as_list() == [None, 1, 1, 512]\n",
    "# make sure that first three dimensions are the same ([None,1,1])\n",
    "assert can_be_concatenated(conv5, conv4)\n",
    "#conv5 = UpSampling2D(2)(conv5)\n",
    "#assert conv5.shape.as_list() == [None, 2, 2, 512]\n",
    "\n",
    "# Here is where changes are necessary\n",
    "# conv4: [None, 1, 1, 256]\n",
    "# conv5: [None, 2, 2, 512]\n",
    "up6 = Concatenate()([conv5, conv4])\n",
    "conv6 = Conv2D(256, 3, 3, activation='relu', padding='same')(up6)\n",
    "\n",
    "model = Model(inputs,outputs=conv6)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(input_shape)\n",
    "conv1 = Conv2D(32, 3, 3, activation='relu', padding='same')(inputs)\n",
    "conv1 = Conv2D(32, 3, 3, activation='relu', padding='same')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2), padding='same')(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, 3, 3, activation='relu', padding='same')(pool1)\n",
    "conv2 = Conv2D(64, 3, 3, activation='relu', padding='same')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2), padding='same')(conv2)\n",
    "\n",
    "conv3 = Conv2D(128, 3, 3, activation='relu', padding='same')(pool2)\n",
    "conv3 = Conv2D(128, 3, 3, activation='relu', padding='same')(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2), padding='same')(conv3)\n",
    "\n",
    "conv4 = Conv2D(256, 3, 3, activation='relu', padding='same')(pool3)\n",
    "conv4 = Conv2D(256, 3, 3, activation='relu', padding='same')(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2), padding='same')(conv4)\n",
    "\n",
    "conv5 = Conv2D(512, 3, 3, activation='relu', padding='same')(pool4)\n",
    "conv5 = Conv2D(512, 3, 3, activation='relu', padding='same')(conv5)\n",
    "# Dimension 0 in both shapes must be equal, but are 2 and 1. Shapes are [2,512] and [1,256]. for '{{node tf.keras.backend.concatenate/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](Placeholder, Placeholder_1, tf.keras.backend.concatenate/concat/axis)'\n",
    "# with input shapes: [?,2,2,512], [?,1,1,256], [] and with computed input tensors: input[2] = <1>.\n",
    "up6 = concat([UpSampling2D(size=(2, 2))(conv5), conv4], axis=0)\n",
    "# up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=1)\n",
    "# up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], mode='concat', concat_axis=1)\n",
    "conv6 = Conv2D(256, 3, 3, activation='relu', padding='same')(up6)\n",
    "conv6 = Conv2D(256, 3, 3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=1)\n",
    "conv7 = Conv2D(128, 3, 3, activation='relu', padding='same')(up7)\n",
    "conv7 = Conv2D(128, 3, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=1)\n",
    "conv8 = Conv2D(64, 3, 3, activation='relu', padding='same')(up8)\n",
    "conv8 = Conv2D(64, 3, 3, activation='relu', padding='same')(conv8)\n",
    "\n",
    "up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=1)\n",
    "conv9 = Conv2D(32, 3, 3, activation='relu', padding='same')(up9)\n",
    "conv9 = Conv2D(32, 3, 3, activation='relu', padding='same')(conv9)\n",
    "\n",
    "conv10 = Conv2D(N_Cls, 1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "model = Model(input=inputs, output=conv10)\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=[jaccard_coef, jaccard_coef_int, 'accuracy'])\n",
    "return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 2, 2, 512), (None, 1, 1, 256)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27599/114595976.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msmpl_conv5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUpSampling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcon1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msmpl_conv5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcon1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#model.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ssd2/development/satellite_imagery/.venv/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    977\u001b[0m                                                 input_list)\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ssd2/development/satellite_imagery/.venv/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1112\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1113\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1115\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ssd2/development/satellite_imagery/.venv/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ssd2/development/satellite_imagery/.venv/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    884\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ssd2/development/satellite_imagery/.venv/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2657\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ssd2/development/satellite_imagery/.venv/lib/python3.8/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ssd2/development/satellite_imagery/.venv/lib/python3.8/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    513\u001b[0m             shape[axis] for shape in shape_set if shape[axis] is not None)\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_dims\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 2, 2, 512), (None, 1, 1, 256)]"
     ]
    }
   ],
   "source": [
    "# Does not work because\n",
    "# s_c5: [None, 2, 2, 512]\n",
    "# c4:   [None, 1, 1, 256]\n",
    "# c4 should be [None, 2, 2, 256]\n",
    "con1 = Concatenate()([smpl_conv5, conv4])\n",
    "model = Model(inputs,outputs=con1)\n",
    "#model.summary()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c67e99029a97bce0befb9c939a8ea5865a8f96efa4c403d841e1548eb989cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
